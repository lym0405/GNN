"""
Phase 5: ì¶©ê²© ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± (Shock Injection)
=============================================
ê³µê¸‰ë§ ë„¤íŠ¸ì›Œí¬ì— ì¶©ê²©ì„ ì£¼ì…í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜
"""

import numpy as np
import torch
import pandas as pd
from pathlib import Path
from typing import List, Dict, Set, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class ShockInjector:
    """
    ê³µê¸‰ë§ ì¶©ê²© ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    
    Parameters
    ----------
    network_df : pd.DataFrame
        ë„¤íŠ¸ì›Œí¬ ë°ì´í„°
    firm_features : Optional[np.ndarray]
        ê¸°ì—… features (Optional)
    """
    
    def __init__(
        self,
        network_df: pd.DataFrame,
        firm_features: Optional[np.ndarray] = None
    ):
        self.network_df = network_df
        self.firm_features = firm_features
        
        # ì›ë³¸ ë°ì´í„° ë°±ì—…
        self.original_network = network_df.copy()
        if firm_features is not None:
            self.original_features = firm_features.copy()
        
        logger.info(f"âœ… ShockInjector ì´ˆê¸°í™”")
        logger.info(f"   - ë„¤íŠ¸ì›Œí¬ ì—£ì§€: {len(network_df):,}ê°œ")
        if firm_features is not None:
            logger.info(f"   - ê¸°ì—… Features: {firm_features.shape}")
    
    def inject_edge_deletion(
        self,
        source_indices: List[int],
        target_indices: List[int],
        deletion_ratio: float = 1.0
    ) -> Tuple[pd.DataFrame, Dict]:
        """
        ì—£ì§€ ì‚­ì œ ì¶©ê²© ì£¼ì…
        
        íŠ¹ì • ê³µê¸‰ì â†’ ìˆ˜ìš”ì ê°„ì˜ ê±°ë˜ë¥¼ ì‚­ì œ
        
        Parameters
        ----------
        source_indices : List[int]
            ê³µê¸‰ì ë…¸ë“œ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        target_indices : List[int]
            ìˆ˜ìš”ì ë…¸ë“œ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        deletion_ratio : float
            ì‚­ì œ ë¹„ìœ¨ (0.0~1.0), 1.0 = ì „ë¶€ ì‚­ì œ
        
        Returns
        -------
        shocked_network : pd.DataFrame
            ì¶©ê²© í›„ ë„¤íŠ¸ì›Œí¬
        shock_info : Dict
            ì¶©ê²© ì •ë³´
        """
        logger.info(f"ğŸ”¨ ì—£ì§€ ì‚­ì œ ì¶©ê²© ì£¼ì…")
        logger.info(f"   - ê³µê¸‰ì: {len(source_indices):,}ê°œ")
        logger.info(f"   - ìˆ˜ìš”ì: {len(target_indices):,}ê°œ")
        logger.info(f"   - ì‚­ì œ ë¹„ìœ¨: {deletion_ratio:.1%}")
        
        # ì›ë³¸ì—ì„œ ì‹œì‘
        shocked_network = self.original_network.copy()
        
        # ì»¬ëŸ¼ëª… í™•ì¸
        src_col, dst_col = self._get_edge_columns(shocked_network)
        
        # firm_to_idx ì—­ë§¤í•‘ í•„ìš” (ì¸ë±ìŠ¤ â†’ firm_id)
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì¸ë±ìŠ¤ë¥¼ ì§ì ‘ ë¹„êµ
        # ì‹¤ì œë¡œëŠ” firm_to_idx ì—­ë§¤í•‘ í•„ìš”
        
        # ì‚­ì œ ëŒ€ìƒ ì°¾ê¸°
        # ì„ì‹œ: firm_idë¥¼ ì¸ë±ìŠ¤ë¡œ ê°€ì •
        delete_mask = (
            shocked_network[src_col].isin(source_indices) &
            shocked_network[dst_col].isin(target_indices)
        )
        
        deleted_edges = shocked_network[delete_mask]
        
        # ì‚­ì œ ë¹„ìœ¨ ì ìš©
        if deletion_ratio < 1.0:
            n_to_delete = int(len(deleted_edges) * deletion_ratio)
            deleted_edges = deleted_edges.sample(n=n_to_delete, random_state=42)
        
        # ì‚­ì œ ì‹¤í–‰
        shocked_network = shocked_network[~shocked_network.index.isin(deleted_edges.index)]
        
        shock_info = {
            'type': 'edge_deletion',
            'deleted_edges_count': len(deleted_edges),
            'remaining_edges_count': len(shocked_network),
            'deletion_ratio': deletion_ratio,
            'source_indices': source_indices,
            'target_indices': target_indices,
            'deleted_edges': deleted_edges,
        }
        
        logger.info(f"   âœ“ ì‚­ì œëœ ì—£ì§€: {len(deleted_edges):,}ê°œ")
        logger.info(f"   âœ“ ë‚¨ì€ ì—£ì§€: {len(shocked_network):,}ê°œ")
        
        return shocked_network, shock_info
    
    def inject_node_disruption(
        self,
        node_indices: List[int],
        disruption_ratio: float = 1.0,
        feature_columns: Optional[List[str]] = None
    ) -> Tuple[Optional[np.ndarray], Dict]:
        """
        ë…¸ë“œ ê¸°ëŠ¥ ì¥ì•  ì¶©ê²© ì£¼ì…
        
        íŠ¹ì • ê¸°ì—…ì˜ ìƒì‚°/ë§¤ì¶œ ëŠ¥ë ¥ì„ 0ìœ¼ë¡œ ì„¤ì •
        
        Parameters
        ----------
        node_indices : List[int]
            ì¶©ê²© ëŒ€ìƒ ë…¸ë“œ ì¸ë±ìŠ¤
        disruption_ratio : float
            ì¥ì•  ë¹„ìœ¨ (0.0~1.0)
        feature_columns : Optional[List[str]]
            ì˜í–¥ë°›ì„ feature ì»¬ëŸ¼ (Noneì´ë©´ ì „ì²´)
        
        Returns
        -------
        shocked_features : np.ndarray
            ì¶©ê²© í›„ features
        shock_info : Dict
            ì¶©ê²© ì •ë³´
        """
        if self.firm_features is None:
            logger.warning("âš ï¸  Features ì—†ìŒ, ì¶©ê²© ì£¼ì… ë¶ˆê°€")
            return None, {}
        
        logger.info(f"ğŸ”¨ ë…¸ë“œ ê¸°ëŠ¥ ì¥ì•  ì¶©ê²© ì£¼ì…")
        logger.info(f"   - ëŒ€ìƒ ë…¸ë“œ: {len(node_indices):,}ê°œ")
        logger.info(f"   - ì¥ì•  ë¹„ìœ¨: {disruption_ratio:.1%}")
        
        # ì›ë³¸ì—ì„œ ì‹œì‘
        shocked_features = self.original_features.copy()
        
        # ì¥ì•  ì ìš©
        for node_idx in node_indices:
            if node_idx < len(shocked_features):
                if feature_columns is None:
                    # ì „ì²´ featuresë¥¼ disruption_ratioë§Œí¼ ê°ì†Œ
                    shocked_features[node_idx] *= (1 - disruption_ratio)
                else:
                    # íŠ¹ì • featureë§Œ ê°ì†Œ
                    # (ì‹¤ì œë¡œëŠ” feature ì´ë¦„ â†’ ì¸ë±ìŠ¤ ë§¤í•‘ í•„ìš”)
                    pass
        
        shock_info = {
            'type': 'node_disruption',
            'affected_nodes_count': len(node_indices),
            'disruption_ratio': disruption_ratio,
            'node_indices': node_indices,
        }
        
        logger.info(f"   âœ“ ë…¸ë“œ ì¥ì•  ì ìš© ì™„ë£Œ")
        
        return shocked_features, shock_info
    
    def inject_supply_cut(
        self,
        supplier_indices: List[int],
        buyer_indices: List[int],
        cut_ratio: float = 1.0
    ) -> Tuple[pd.DataFrame, Optional[np.ndarray], Dict]:
        """
        ê³µê¸‰ ì°¨ë‹¨ ì¶©ê²© (ì—£ì§€ ì‚­ì œ + ë…¸ë“œ ì¥ì•  ë³µí•©)
        
        Parameters
        ----------
        supplier_indices : List[int]
            ê³µê¸‰ì ì¸ë±ìŠ¤
        buyer_indices : List[int]
            ìˆ˜ìš”ì ì¸ë±ìŠ¤
        cut_ratio : float
            ì°¨ë‹¨ ë¹„ìœ¨
        
        Returns
        -------
        shocked_network : pd.DataFrame
        shocked_features : Optional[np.ndarray]
        shock_info : Dict
        """
        logger.info(f"ğŸ”¨ ê³µê¸‰ ì°¨ë‹¨ ì¶©ê²© ì£¼ì… (ë³µí•©)")
        
        # 1. ì—£ì§€ ì‚­ì œ
        shocked_network, edge_info = self.inject_edge_deletion(
            source_indices=supplier_indices,
            target_indices=buyer_indices,
            deletion_ratio=cut_ratio
        )
        
        # 2. ê³µê¸‰ì ë…¸ë“œ ì¥ì• 
        shocked_features, node_info = self.inject_node_disruption(
            node_indices=supplier_indices,
            disruption_ratio=cut_ratio
        )
        
        shock_info = {
            'type': 'supply_cut',
            'edge_deletion': edge_info,
            'node_disruption': node_info,
            'cut_ratio': cut_ratio,
        }
        
        logger.info(f"   âœ“ ë³µí•© ì¶©ê²© ì£¼ì… ì™„ë£Œ")
        
        return shocked_network, shocked_features, shock_info
    
    def _get_edge_columns(self, df: pd.DataFrame) -> Tuple[str, str]:
        """ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ì˜ source, target ì»¬ëŸ¼ ì°¾ê¸°"""
        if 'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸' in df.columns and 'ê±°ë˜ì²˜ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸' in df.columns:
            return 'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸', 'ê±°ë˜ì²˜ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'
        elif 'source' in df.columns and 'target' in df.columns:
            return 'source', 'target'
        elif 'src' in df.columns and 'dst' in df.columns:
            return 'src', 'dst'
        else:
            logger.warning("âš ï¸  ì—£ì§€ ì»¬ëŸ¼ëª… í™•ì¸ í•„ìš”")
            return df.columns[0], df.columns[1]
    
    def reset(self):
        """ì›ë³¸ ë°ì´í„°ë¡œ ë¦¬ì…‹"""
        self.network_df = self.original_network.copy()
        if self.firm_features is not None:
            self.firm_features = self.original_features.copy()
        
        logger.info("âœ… ì›ë³¸ ë°ì´í„°ë¡œ ë¦¬ì…‹ ì™„ë£Œ")


# ============================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================

def create_shock_scenario(
    network_df: pd.DataFrame,
    supplier_indices: List[int],
    buyer_indices: List[int],
    shock_type: str = 'edge_deletion',
    shock_intensity: float = 1.0,
    firm_features: Optional[np.ndarray] = None
) -> Tuple[pd.DataFrame, Optional[np.ndarray], Dict]:
    """
    ì¶©ê²© ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± (ê°„í¸ í•¨ìˆ˜)
    
    Parameters
    ----------
    network_df : pd.DataFrame
    supplier_indices : List[int]
    buyer_indices : List[int]
    shock_type : str
        'edge_deletion', 'node_disruption', 'supply_cut'
    shock_intensity : float
        ì¶©ê²© ê°•ë„ (0.0~1.0)
    firm_features : Optional[np.ndarray]
    
    Returns
    -------
    shocked_network : pd.DataFrame
    shocked_features : Optional[np.ndarray]
    shock_info : Dict
    """
    injector = ShockInjector(network_df, firm_features)
    
    if shock_type == 'edge_deletion':
        shocked_network, shock_info = injector.inject_edge_deletion(
            source_indices=supplier_indices,
            target_indices=buyer_indices,
            deletion_ratio=shock_intensity
        )
        return shocked_network, firm_features, shock_info
    
    elif shock_type == 'node_disruption':
        shocked_features, shock_info = injector.inject_node_disruption(
            node_indices=supplier_indices,
            disruption_ratio=shock_intensity
        )
        return network_df, shocked_features, shock_info
    
    elif shock_type == 'supply_cut':
        return injector.inject_supply_cut(
            supplier_indices=supplier_indices,
            buyer_indices=buyer_indices,
            cut_ratio=shock_intensity
        )
    
    else:
        raise ValueError(f"Unknown shock_type: {shock_type}")


def propagate_shock_gpu(
    adj_matrix: torch.sparse.FloatTensor,
    initial_shock: torch.Tensor,
    steps: int = 30,
    activation_fn: str = 'sigmoid',
    threshold: float = 0.5
) -> torch.Tensor:
    """
    GPU ê¸°ë°˜ ë³‘ë ¬ ì¶©ê²© ì „íŒŒ ì‹œë®¬ë ˆì´ì…˜ (ë°°ì¹˜ ì²˜ë¦¬)
    
    [ìµœì í™”] ìˆœì°¨ì  ë…¸ë“œ ë°˜ë³µ ëŒ€ì‹  í–‰ë ¬ ê³±ìœ¼ë¡œ í•œ ë²ˆì— ì²˜ë¦¬
    - Before: for node in nodes: ... â†’ O(N Ã— steps)
    - After: Sparse Matrix Multiplication â†’ O(nnz Ã— steps)
    - ë°°ì¹˜ ì²˜ë¦¬: 100ê°œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í•œ ë²ˆì˜ ì—°ì‚°ìœ¼ë¡œ ì²˜ë¦¬
    
    Parameters
    ----------
    adj_matrix : torch.sparse.FloatTensor
        ì¸ì ‘ í–‰ë ¬ (N Ã— N, sparse)
    initial_shock : torch.Tensor
        ì´ˆê¸° ì¶©ê²© ë²¡í„°
        - Shape: (batch_size, N) ë˜ëŠ” (N,)
        - ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥
    steps : int
        ì „íŒŒ ìŠ¤í… ìˆ˜
    activation_fn : str
        í™œì„±í™” í•¨ìˆ˜ ('sigmoid', 'relu', 'threshold')
    threshold : float
        ì„ê³„ê°’ (activation_fn='threshold'ì¼ ë•Œ)
    
    Returns
    -------
    history : torch.Tensor
        ì¶©ê²© ì „íŒŒ íˆìŠ¤í† ë¦¬
        - Shape: (steps, batch_size, N)
    
    Notes
    -----
    ë³‘ë ¬ ì²˜ë¦¬ ì˜ˆì‹œ:
    - 100ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì¶©ê²© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë™ì‹œì— ì‹œë®¬ë ˆì´ì…˜
    - GPU ë©”ëª¨ë¦¬ê°€ í—ˆìš©í•˜ëŠ” í•œ ë¬´í•œì • í™•ì¥ ê°€ëŠ¥
    - ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ë¹„ 100ë°° ì‹œë‚˜ë¦¬ì˜¤ë„ ê±°ì˜ ê°™ì€ ì‹œê°„
    
    Example
    -------
    >>> adj = torch.sparse_coo_tensor(...)  # N Ã— N
    >>> # 100ê°œ ì‹œë‚˜ë¦¬ì˜¤
    >>> initial_shocks = torch.randn(100, N)  # ê° ì‹œë‚˜ë¦¬ì˜¤ë§ˆë‹¤ ë‹¤ë¥¸ ì¶©ê²©
    >>> history = propagate_shock_gpu(adj, initial_shocks, steps=30)
    >>> history.shape  # (30, 100, N)
    """
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # GPUë¡œ ì´ë™
    current_status = initial_shock.to(device)
    adj = adj_matrix.to(device)
    
    # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì°¨ì› í™•ì¸
    if current_status.dim() == 1:
        current_status = current_status.unsqueeze(0)  # (N,) â†’ (1, N)
    
    batch_size, num_nodes = current_status.shape
    
    history = []
    
    logger.info(f"ğŸš€ GPU ì¶©ê²© ì „íŒŒ ì‹œì‘")
    logger.info(f"   - Device: {device}")
    logger.info(f"   - Batch Size: {batch_size}")
    logger.info(f"   - ë…¸ë“œ ìˆ˜: {num_nodes:,}")
    logger.info(f"   - Steps: {steps}")
    
    # [ìµœì í™” 2] ì¡°ê¸° ì¢…ë£Œë¥¼ ìœ„í•œ ë³€ìˆ˜
    convergence_threshold = 1e-4  # ë³€í™”ëŸ‰ì´ ì´ ê°’ ì´í•˜ë©´ ìˆ˜ë ´ìœ¼ë¡œ íŒë‹¨
    prev_status = None
    
    for step in range(steps):
        # [ìµœì í™”] Sparse Matrix Multiplication
        # for node in nodes: ... ëŒ€ì‹  í–‰ë ¬ ê³± í•œ ë²ˆ
        # 100ê°œì˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í•œ ë²ˆì˜ ì—°ì‚°ìœ¼ë¡œ ì²˜ë¦¬ (Batch Processing)
        
        # current_status: (batch_size, N)
        # adj: (N, N) sparse
        # result: (batch_size, N)
        
        # torch.sparse.mmì€ 2Dë§Œ ì§€ì›í•˜ë¯€ë¡œ transpose í™œìš©
        impact = torch.sparse.mm(adj, current_status.t()).t()
        
        # í™œì„±í™” í•¨ìˆ˜ ì ìš©
        if activation_fn == 'sigmoid':
            current_status = torch.sigmoid(impact)
        elif activation_fn == 'relu':
            current_status = torch.relu(impact)
        elif activation_fn == 'threshold':
            current_status = (impact > threshold).float()
        else:
            current_status = impact  # identity
        
        history.append(current_status.clone())
        
        # [ìµœì í™” 2] ì¡°ê¸° ì¢…ë£Œ (Early Stopping)
        # ë” ì´ìƒ ì¶©ê²©ì´ ì „íŒŒë˜ì§€ ì•ŠëŠ” Steady State ë„ë‹¬ ì‹œ ì¢…ë£Œ
        if prev_status is not None:
            # ëª¨ë“  ë°°ì¹˜ì— ëŒ€í•´ ë³€í™”ëŸ‰ ê³„ì‚°
            diff = torch.abs(current_status - prev_status).max().item()
            
            if diff < convergence_threshold:
                logger.info(
                    f"   ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ (Step {step+1}/{steps}): "
                    f"ìˆ˜ë ´ ê°ì§€ (diff={diff:.6f})"
                )
                break
        
        prev_status = current_status.clone()
        
        if (step + 1) % 10 == 0:
            logger.info(f"   âœ“ Step {step+1}/{steps}")
    
    # Stack: (steps, batch_size, N)
    history_tensor = torch.stack(history)
    
    logger.info(f"âœ… GPU ì¶©ê²© ì „íŒŒ ì™„ë£Œ")
    logger.info(f"   - ì‹¤ì œ Steps: {len(history)}/{steps}")
    logger.info(f"   - Output Shape: {history_tensor.shape}")
    
    return history_tensor


def propagate_shock_cpu(
    adj_matrix: np.ndarray,
    initial_shock: np.ndarray,
    steps: int = 30,
    convergence_threshold: float = 1e-4
) -> np.ndarray:
    """
    CPU ê¸°ë°˜ ì¶©ê²© ì „íŒŒ (ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤)
    
    GPUê°€ ì—†ëŠ” í™˜ê²½ì„ ìœ„í•œ í´ë°±
    [ìµœì í™” 2] ì¡°ê¸° ì¢…ë£Œ í¬í•¨
    
    Parameters
    ----------
    adj_matrix : np.ndarray
        ì¸ì ‘ í–‰ë ¬ (N Ã— N)
    initial_shock : np.ndarray
        ì´ˆê¸° ì¶©ê²© ë²¡í„° (N,)
    steps : int
        ìµœëŒ€ ì „íŒŒ ìŠ¤í… ìˆ˜
    convergence_threshold : float
        ìˆ˜ë ´ íŒë‹¨ ì„ê³„ê°’
    
    Returns
    -------
    history : np.ndarray
        ì¶©ê²© ì „íŒŒ íˆìŠ¤í† ë¦¬ (actual_steps, N)
    """
    current_status = initial_shock.copy()
    history = []
    prev_status = None
    
    for step in range(steps):
        # í–‰ë ¬ ê³±
        impact = adj_matrix @ current_status
        current_status = 1 / (1 + np.exp(-impact))  # sigmoid
        history.append(current_status.copy())
        
        # [ìµœì í™” 2] ì¡°ê¸° ì¢…ë£Œ
        if prev_status is not None:
            diff = np.abs(current_status - prev_status).max()
            if diff < convergence_threshold:
                logger.info(
                    f"   ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ (Step {step+1}/{steps}): "
                    f"ìˆ˜ë ´ ê°ì§€ (diff={diff:.6f})"
                )
                break
        
        prev_status = current_status.copy()
    
    return np.array(history)
