"""
Static Graph Builder for Phase 2
=================================
Phase 1 ë ˆì‹œí”¼ + ì¬ë¬´/TIS ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ PyG Data ê°ì²´ ìƒì„±
"""

import numpy as np
import pandas as pd
import pickle
import torch
from scipy.sparse import load_npz, csr_matrix
from pathlib import Path
import logging
from typing import Dict, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class StaticGraphBuilder:
    """ì •ì  ê·¸ë˜í”„ ë°ì´í„° ë¹Œë”"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.raw_dir = self.data_dir / "raw"
        self.processed_dir = self.data_dir / "processed"
        
    def build_static_data(
        self,
        use_simple_features: bool = True
    ) -> Tuple[torch.Tensor, torch.Tensor, np.ndarray, list]:
        """
        ì •ì  ê·¸ë˜í”„ ë°ì´í„° êµ¬ì¶•
        
        Parameters
        ----------
        use_simple_features : bool
            True: 73ì°¨ì› (ê°„ì†Œí™”), False: 197ì°¨ì› (ì „ì²´)
        
        Returns
        -------
        X : torch.Tensor, shape (N, D)
            ë…¸ë“œ í”¼ì²˜ í–‰ë ¬
        edge_index : torch.Tensor, shape (2, E)
            ì—£ì§€ ì¸ë±ìŠ¤ (PyG í˜•ì‹)
        edge_attr : np.ndarray, shape (E,)
            ì—£ì§€ ì†ì„± (ê±°ë˜ ê¸ˆì•¡)
        firm_ids : list
            ê¸°ì—… ID ë¦¬ìŠ¤íŠ¸
        """
        logger.info("=" * 70)
        logger.info("ğŸ—ï¸  ì •ì  ê·¸ë˜í”„ ë°ì´í„° êµ¬ì¶• ì‹œì‘")
        logger.info("=" * 70)
        
        # 1. ê¸°ì—… ì¸ë±ìŠ¤ ë¡œë“œ
        firm_ids = self._load_firm_ids()
        N = len(firm_ids)
        logger.info(f"âœ“ ê¸°ì—… ìˆ˜: {N:,}")
        
        # 2. í”¼ì²˜ ìƒì„±
        if use_simple_features:
            X = self._build_simple_features(firm_ids)
            logger.info(f"âœ“ í”¼ì²˜ ì°¨ì›: {X.shape[1]} (ê°„ì†Œí™” ë²„ì „)")
        else:
            X = self._build_full_features(firm_ids)
            logger.info(f"âœ“ í”¼ì²˜ ì°¨ì›: {X.shape[1]} (ì „ì²´ ë²„ì „)")
        
        # 3. ì—£ì§€ ë¡œë“œ (H í–‰ë ¬)
        edge_index, edge_attr = self._load_edges(firm_ids)
        logger.info(f"âœ“ ì—£ì§€ ìˆ˜: {edge_index.shape[1]:,}")
        
        # 4. ì¸ë±ìŠ¤ ì •ë ¬ ë³´ì¥
        X = self._reindex_features(X, firm_ids)
        
        logger.info("=" * 70)
        
        return X, edge_index, edge_attr, firm_ids
    
    def _load_firm_ids(self) -> list:
        """ê¸°ì—… ID ë¡œë“œ"""
        firm_to_idx_path = self.raw_dir / "firm_to_idx_model2.csv"
        df = pd.read_csv(firm_to_idx_path)
        firm_ids = df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'].astype(str).tolist()
        return firm_ids
    
    def _build_simple_features(self, firm_ids: list) -> torch.Tensor:
        """
        ê°„ì†Œí™” í”¼ì²˜ (73ì°¨ì›)
        = ì¬ë¬´4 + ì§€ë¦¬2 + TIS1 + ì‚°ì—…33 + ë ˆì‹œí”¼33
        """
        N = len(firm_ids)
        features = []
        
        # 1. ì¬ë¬´ í”¼ì²˜ (4ì°¨ì›)
        logger.info("  ğŸ“Š ì¬ë¬´ í”¼ì²˜ ìƒì„±...")
        financial = self._load_financial_features(firm_ids)  # (N, 4)
        features.append(financial)
        
        # 2. ì§€ë¦¬ í”¼ì²˜ (2ì°¨ì›)
        logger.info("  ğŸŒ ì§€ë¦¬ í”¼ì²˜ ìƒì„±...")
        geo = self._load_geo_features(firm_ids)  # (N, 2)
        features.append(geo)
        
        # 3. TIS í”¼ì²˜ (1ì°¨ì›)
        logger.info("  âš ï¸  TIS í”¼ì²˜ ìƒì„±...")
        tis = self._load_tis_features(firm_ids)  # (N, 1)
        features.append(tis)
        
        # 4. ì‚°ì—… One-Hot (33ì°¨ì›)
        logger.info("  ğŸ­ ì‚°ì—… í”¼ì²˜ ìƒì„±...")
        industry = self._load_industry_features(firm_ids)  # (N, 33)
        features.append(industry)
        
        # 5. ë ˆì‹œí”¼ í”¼ì²˜ (33ì°¨ì›)
        logger.info("  ğŸ§ª ë ˆì‹œí”¼ í”¼ì²˜ ë¡œë“œ...")
        recipe = self._load_recipe_features(firm_ids)  # (N, 33)
        features.append(recipe)
        
        # ê²°í•©
        X = np.concatenate(features, axis=1).astype(np.float32)
        
        # NaN ì œê±°
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        
        return torch.from_numpy(X)
    
    def _build_full_features(self, firm_ids: list) -> torch.Tensor:
        """ì „ì²´ í”¼ì²˜ (197ì°¨ì›) - ì‚°ì—… ì„ë² ë”© ì¶”ê°€"""
        # ê°„ì†Œí™” ë²„ì „ê³¼ ë™ì¼í•˜ê²Œ êµ¬í˜„ (ë‚˜ì¤‘ì— í™•ì¥ ê°€ëŠ¥)
        return self._build_simple_features(firm_ids)
    
    def _load_financial_features(self, firm_ids: list) -> np.ndarray:
        """ì¬ë¬´ í”¼ì²˜ ë¡œë“œ (4ì°¨ì›)"""
        N = len(firm_ids)
        financial = np.zeros((N, 4), dtype=np.float32)
        
        # ë§¤ì¶œ
        revenue_path = self.raw_dir / "tg_2024_filtered.csv"
        if revenue_path.exists():
            df = pd.read_csv(revenue_path)
            df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'] = df.get('ì—…ì²´ë²ˆí˜¸', df.get('ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸', '')).astype(str)
            revenue_map = dict(zip(df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'], df['tg_2024_final']))
            
            for i, fid in enumerate(firm_ids):
                rev = revenue_map.get(fid, 0)
                financial[i, 0] = np.log1p(rev)  # log(ë§¤ì¶œ + 1)
        
        # ìˆ˜ì¶œì•¡
        export_path = self.raw_dir / "export_estimation_value_final.csv"
        if export_path.exists():
            df = pd.read_csv(export_path)
            df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'] = df.get('ì—…ì²´ë²ˆí˜¸', '').astype(str)
            export_map = dict(zip(df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'], df['export_value']))
            
            for i, fid in enumerate(firm_ids):
                exp = export_map.get(fid, 0)
                financial[i, 1] = np.log1p(exp)  # log(ìˆ˜ì¶œ + 1)
        
        # ìì‚°
        asset_path = self.raw_dir / "asset_final_2024_6ì°¨.csv"
        if asset_path.exists():
            df = pd.read_csv(asset_path)
            df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'] = df.get('ì—…ì²´ë²ˆí˜¸', '').astype(str)
            asset_map = dict(zip(df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'], df['asset']))
            
            for i, fid in enumerate(firm_ids):
                ast = asset_map.get(fid, 0)
                financial[i, 2] = np.log1p(ast)  # log(ìì‚° + 1)
        
        # ìˆ˜ì¶œ/ë§¤ì¶œ ë¹„ìœ¨
        financial[:, 3] = np.where(
            financial[:, 0] > 0,
            financial[:, 1] / financial[:, 0],
            0
        )
        
        return financial
    
    def _load_geo_features(self, firm_ids: list) -> np.ndarray:
        """ì§€ë¦¬ í”¼ì²˜ ë¡œë“œ (2ì°¨ì›)"""
        N = len(firm_ids)
        geo = np.zeros((N, 2), dtype=np.float32)
        
        firm_info_path = self.raw_dir / "vat_20-24_company_list_w_companyinfo_nocutoff_v3_hyundaisteel_hj.csv"
        if firm_info_path.exists():
            df = pd.read_csv(firm_info_path)
            df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'] = df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'].astype(str)
            
            lat_map = dict(zip(df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'], df.get('ìœ„ë„', df.get('latitude', 0))))
            lon_map = dict(zip(df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'], df.get('ê²½ë„', df.get('longitude', 0))))
            
            for i, fid in enumerate(firm_ids):
                geo[i, 0] = lat_map.get(fid, 37.5)  # ê¸°ë³¸ê°’: ì„œìš¸
                geo[i, 1] = lon_map.get(fid, 127.0)
        
        # ì •ê·œí™” (ëŒ€í•œë¯¼êµ­ ë²”ìœ„)
        geo[:, 0] = (geo[:, 0] - 33) / 10  # ìœ„ë„ 33~43
        geo[:, 1] = (geo[:, 1] - 124) / 8  # ê²½ë„ 124~132
        
        return geo
    
    def _load_tis_features(self, firm_ids: list) -> np.ndarray:
        """TIS í”¼ì²˜ ë¡œë“œ (1ì°¨ì›)"""
        N = len(firm_ids)
        tis = np.zeros((N, 1), dtype=np.float32)
        
        tis_path = self.raw_dir / "shock_after_P_v2.csv"
        if tis_path.exists():
            df = pd.read_csv(tis_path)
            df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'] = df.get('ì—…ì²´ë²ˆí˜¸', '').astype(str)
            tis_map = dict(zip(df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'], df['TIS']))
            
            for i, fid in enumerate(firm_ids):
                tis[i, 0] = tis_map.get(fid, 0)
        
        # ì •ê·œí™” (0~1)
        tis = np.clip(tis, 0, 1)
        
        # ë³„ë„ ì €ì¥ (Phase 3ì—ì„œ ì‚¬ìš©)
        tis_path = self.processed_dir / "tis_score_normalized.npy"
        np.save(tis_path, tis)
        logger.info(f"    ğŸ’¾ TIS ì €ì¥: {tis_path}")
        
        return tis
    
    def _load_industry_features(self, firm_ids: list) -> np.ndarray:
        """ì‚°ì—… One-Hot í”¼ì²˜ (33ì°¨ì›)"""
        N = len(firm_ids)
        industry = np.zeros((N, 33), dtype=np.float32)
        
        firm_info_path = self.raw_dir / "vat_20-24_company_list_w_companyinfo_nocutoff_v3_hyundaisteel_hj.csv"
        if firm_info_path.exists():
            df = pd.read_csv(firm_info_path)
            df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'] = df['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸'].astype(str)
            
            sector_map = {}
            for _, row in df.iterrows():
                fid = row['ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸']
                sector_code = row.get('ì‚°ì—…ì½”ë“œ', -1)
                try:
                    sector_idx = int(sector_code) - 1  # 1-based â†’ 0-based
                    if 0 <= sector_idx < 33:
                        sector_map[fid] = sector_idx
                except:
                    pass
            
            for i, fid in enumerate(firm_ids):
                if fid in sector_map:
                    industry[i, sector_map[fid]] = 1.0
        
        return industry
    
    def _load_recipe_features(self, firm_ids: list) -> np.ndarray:
        """ë ˆì‹œí”¼ í”¼ì²˜ ë¡œë“œ (33ì°¨ì›)"""
        N = len(firm_ids)
        recipe = np.zeros((N, 33), dtype=np.float32)
        
        recipe_path = self.processed_dir / "disentangled_recipes.pkl"
        if recipe_path.exists():
            with open(recipe_path, 'rb') as f:
                recipe_dict = pickle.load(f)
            
            for i, fid in enumerate(firm_ids):
                if fid in recipe_dict:
                    recipe[i, :] = recipe_dict[fid]
                else:
                    # ë ˆì‹œí”¼ ì—†ìœ¼ë©´ ê· ë“± ë¶„í¬
                    recipe[i, :] = 1.0 / 33
            
            logger.info(f"    âœ“ ë ˆì‹œí”¼ ë¡œë“œ: {len(recipe_dict)} ê¸°ì—…")
        else:
            logger.warning(f"    âš ï¸  ë ˆì‹œí”¼ íŒŒì¼ ì—†ìŒ: {recipe_path}")
            # ê· ë“± ë¶„í¬ë¡œ ì´ˆê¸°í™”
            recipe[:, :] = 1.0 / 33
        
        # ìºì‹±
        cache_path = self.processed_dir / "recipe_features_cache.npy"
        np.save(cache_path, recipe)
        logger.info(f"    ğŸ’¾ ë ˆì‹œí”¼ ìºì‹œ ì €ì¥: {cache_path}")
        
        return recipe
    
    def _load_edges(self, firm_ids: list) -> Tuple[torch.Tensor, np.ndarray]:
        """ì—£ì§€ ë¡œë“œ (H í–‰ë ¬)"""
        H_path = self.raw_dir / "H_csr_model2.npz"
        H = load_npz(H_path)
        
        # COO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        H_coo = H.tocoo()
        
        # PyG í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        edge_index = np.vstack([H_coo.row, H_coo.col])
        edge_index = torch.from_numpy(edge_index).long()
        
        # ì—£ì§€ ì†ì„± (ê±°ë˜ ê¸ˆì•¡)
        edge_attr = H_coo.data.astype(np.float32)
        
        # Log ìŠ¤ì¼€ì¼ë§
        edge_attr = np.log1p(edge_attr)
        
        return edge_index, edge_attr
    
    def _reindex_features(self, X: torch.Tensor, firm_ids: list) -> torch.Tensor:
        """ì¸ë±ìŠ¤ ì •ë ¬ ë³´ì¥"""
        # ì´ë¯¸ firm_to_idx_model2.csv ìˆœì„œëŒ€ë¡œ ë¡œë“œí–ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return X
    
    def save_features(self, X: torch.Tensor):
        """í”¼ì²˜ í–‰ë ¬ ì €ì¥"""
        X_path = self.processed_dir / "X_feature_matrix.npy"
        np.save(X_path, X.numpy())
        logger.info(f"ğŸ’¾ í”¼ì²˜ í–‰ë ¬ ì €ì¥: {X_path}")


if __name__ == "__main__":
    builder = StaticGraphBuilder()
    X, edge_index, edge_attr, firm_ids = builder.build_static_data(use_simple_features=True)
    
    print(f"\nâœ… ê·¸ë˜í”„ ë°ì´í„° ìƒì„± ì™„ë£Œ")
    print(f"   - ë…¸ë“œ ìˆ˜: {X.shape[0]:,}")
    print(f"   - í”¼ì²˜ ì°¨ì›: {X.shape[1]}")
    print(f"   - ì—£ì§€ ìˆ˜: {edge_index.shape[1]:,}")
    print(f"   - ì—£ì§€ ì†ì„± ë²”ìœ„: {edge_attr.min():.2f} ~ {edge_attr.max():.2f}")
    
    builder.save_features(X)
