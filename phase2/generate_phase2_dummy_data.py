"""
Phase 2 Dummy Data Generator
=============================
Phase 2 í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í†µí•© ë”ë¯¸ ë°ì´í„° ìƒì„± (Phase 1 í¬í•¨)

ì‹¤í–‰ ë°©ë²•:
    python generate_phase2_dummy_data.py --n_firms 1000
"""

import numpy as np
import pandas as pd
from scipy.sparse import random, save_npz
from pathlib import Path
import pickle
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def generate_phase2_test_data(
    n_firms: int = 1000,
    density: float = 0.02,
    output_dir: str = "../data"
):
    """
    Phase 2 í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì™„ì „í•œ ë”ë¯¸ ë°ì´í„° ìƒì„±
    
    í¬í•¨:
    - Phase 1 ì¶œë ¥ (disentangled_recipes.pkl)
    - ëª¨ë“  ì›ë³¸ ë°ì´í„° (H í–‰ë ¬, ê¸°ì—…ì •ë³´, ì¬ë¬´ ë“±)
    """
    
    output_path = Path(output_dir)
    raw_path = output_path / "raw"
    processed_path = output_path / "processed"
    
    raw_path.mkdir(parents=True, exist_ok=True)
    processed_path.mkdir(parents=True, exist_ok=True)
    
    logger.info("=" * 70)
    logger.info(f"ğŸ² Phase 2 í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (N={n_firms})")
    logger.info("=" * 70)
    
    # ============================================================
    # 1. ì›ë³¸ ë°ì´í„° ìƒì„± (Phase 1ìš©)
    # ============================================================
    
    logger.info("\n[1/3] ì›ë³¸ ë°ì´í„° ìƒì„±...")
    
    # IO í…Œì´ë¸”
    A_matrix = np.random.rand(33, 33).astype(np.float32)
    A_matrix = A_matrix / A_matrix.sum(axis=1, keepdims=True)
    sector_names = [f'sector_{i:02d}' for i in range(1, 34)]
    A_df = pd.DataFrame(A_matrix, index=sector_names, columns=sector_names)
    A_df.to_csv(raw_path / "A_33.csv")
    logger.info("   âœ“ A_33.csv")
    
    # H í–‰ë ¬ (ê±°ë˜ ë„¤íŠ¸ì›Œí¬)
    H_matrix = random(n_firms, n_firms, density=density, format='csr', random_state=42)
    H_matrix = H_matrix * 1e9
    save_npz(raw_path / "H_csr_model2.npz", H_matrix)
    logger.info(f"   âœ“ H_csr_model2.npz (ë°€ë„: {density*100:.2f}%)")
    
    # ê¸°ì—… ì¸ë±ìŠ¤ ë§¤í•‘
    firm_ids = [f'firm_{i:06d}' for i in range(n_firms)]
    firm_to_idx = pd.DataFrame({
        'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': firm_ids,
        'idx': range(n_firms)
    })
    firm_to_idx.to_csv(raw_path / "firm_to_idx_model2.csv", index=False)
    logger.info("   âœ“ firm_to_idx_model2.csv")
    
    # ê¸°ì—… ì •ë³´
    sector_codes = np.random.randint(1, 34, size=n_firms)
    latitudes = np.random.uniform(33, 43, size=n_firms)
    longitudes = np.random.uniform(124, 132, size=n_firms)
    
    firm_info = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': firm_ids,
        'ì‚°ì—…ì½”ë“œ': sector_codes,
        'ìœ„ë„': latitudes,
        'ê²½ë„': longitudes,
        'ê¸°ì—…ëª…': [f'Company_{i}' for i in range(n_firms)]
    })
    firm_info.to_csv(
        raw_path / "vat_20-24_company_list_w_companyinfo_nocutoff_v3_hyundaisteel_hj.csv",
        index=False
    )
    logger.info("   âœ“ ê¸°ì—… ì •ë³´ CSV")
    
    # ë§¤ì¶œ ë°ì´í„°
    revenues = np.random.lognormal(mean=20, sigma=2, size=n_firms)
    revenue_df = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': firm_ids,
        'tg_2024_final': revenues
    })
    revenue_df.to_csv(raw_path / "tg_2024_filtered.csv", index=False)
    logger.info("   âœ“ tg_2024_filtered.csv")
    
    # ìˆ˜ì¶œì•¡
    export_values = revenues * np.random.uniform(0, 0.5, size=n_firms)
    export_df = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'export_value': export_values
    })
    export_df.to_csv(raw_path / "export_estimation_value_final.csv", index=False)
    logger.info("   âœ“ export_estimation_value_final.csv")
    
    # ìì‚°
    assets = revenues * np.random.uniform(1, 5, size=n_firms)
    asset_df = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'asset': assets
    })
    asset_df.to_csv(raw_path / "asset_final_2024_6ì°¨.csv", index=False)
    logger.info("   âœ“ asset_final_2024_6ì°¨.csv")
    
    # TIS ì ìˆ˜
    tis_scores = np.random.beta(2, 5, size=n_firms)
    tis_df = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'TIS': tis_scores
    })
    tis_df.to_csv(raw_path / "shock_after_P_v2.csv", index=False)
    logger.info("   âœ“ shock_after_P_v2.csv")
    
    # Historical ë°ì´í„° (2020-2023) - Phase 3ìš© ì‹œê³„ì—´ ë„¤íŠ¸ì›Œí¬
    for year in range(2020, 2024):
        # ì´ì „ ë…„ë„ ê±°ë˜ ë°ì´í„° (ì¼ë¶€ë§Œ 2024ë…„ê³¼ ê²¹ì¹¨)
        hist_edges = int(n_firms * density * n_firms * 0.5)
        hist_src = np.random.choice(firm_ids, size=hist_edges)
        hist_dst = np.random.choice(firm_ids, size=hist_edges)
        hist_amount = np.random.exponential(1e8, size=hist_edges)
        
        hist_df = pd.DataFrame({
            'Unnamed: 0': hist_src,       # Phase 3ì—ì„œ sourceë¡œ ì‚¬ìš©
            'Unnamed: 1': hist_dst,        # Phase 3ì—ì„œ targetìœ¼ë¡œ ì‚¬ìš©
            'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': hist_src,
            'ê±°ë˜ì²˜ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': hist_dst,
            'ì´ê³µê¸‰ê¸ˆì•¡': hist_amount
        })
        
        # Phase 3ê°€ ì°¾ëŠ” íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
        hist_path = raw_path / f"posco_network_{year}.csv"
        hist_df.to_csv(hist_path, index=False, encoding='utf-8-sig')
        logger.info(f"   âœ“ posco_network_{year}.csv")
        
        # ê¸°ì¡´ ì´ë¦„ë„ ì €ì¥ (í˜¸í™˜ì„±)
        hist_path_old = raw_path / f"posco_network_capital_consumergoods_removed_{year}.csv"
        hist_df.to_csv(hist_path_old, index=False, encoding='utf-8-sig')
    
    # ============================================================
    # 2. Phase 1 ì¶œë ¥ ìƒì„± (ë ˆì‹œí”¼)
    # ============================================================
    
    logger.info("\n[2/3] Phase 1 ì¶œë ¥ ìƒì„± (ë ˆì‹œí”¼)...")
    
    # ê°„ë‹¨í•œ ë ˆì‹œí”¼ ìƒì„± (ì‚°ì—…ë³„ íŒ¨í„´ ë°˜ì˜)
    recipes = {}
    for i, firm_id in enumerate(firm_ids):
        sector = sector_codes[i] - 1  # 0-based
        
        # í•´ë‹¹ ì‚°ì—…ì— ì§‘ì¤‘ëœ ë ˆì‹œí”¼ ìƒì„±
        recipe = np.random.dirichlet(np.ones(33) * 0.5)
        
        # ìê¸° ì‚°ì—…ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
        recipe[sector] *= 3
        recipe = recipe / recipe.sum()
        
        recipes[firm_id] = recipe.astype(np.float32)
    
    # ì €ì¥
    with open(processed_path / "disentangled_recipes.pkl", 'wb') as f:
        pickle.dump(recipes, f)
    logger.info(f"   âœ“ disentangled_recipes.pkl ({len(recipes)} ê¸°ì—…)")
    
    # B í–‰ë ¬ë„ ì €ì¥ (ì„ íƒì )
    B_matrix = np.array([recipes[fid] for fid in firm_ids])
    np.save(processed_path / "B_matrix.npy", B_matrix)
    logger.info("   âœ“ B_matrix.npy")
    
    # ============================================================
    # 3. í†µê³„ ì¶œë ¥
    # ============================================================
    
    logger.info("\n[3/3] ë°ì´í„° í†µê³„...")
    logger.info(f"   - ê¸°ì—… ìˆ˜: {n_firms:,}")
    logger.info(f"   - ì—£ì§€ ìˆ˜: {H_matrix.nnz:,}")
    logger.info(f"   - ë°€ë„: {H_matrix.nnz / (n_firms ** 2) * 100:.4f}%")
    logger.info(f"   - í‰ê·  ë§¤ì¶œ: {revenues.mean() / 1e6:.2f}M ì›")
    logger.info(f"   - í‰ê·  TIS: {tis_scores.mean():.3f}")
    
    logger.info("\n" + "=" * 70)
    logger.info("âœ… Phase 2 í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    logger.info("=" * 70)
    logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬:")
    logger.info(f"   - {raw_path.absolute()}")
    logger.info(f"   - {processed_path.absolute()}")
    logger.info("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ Phase 2 ì‹¤í–‰:")
    logger.info("    python main_phase2_fixed.py")
    logger.info("=" * 70)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Phase 2 í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±")
    parser.add_argument('--n_firms', type=int, default=1000, help='ê¸°ì—… ìˆ˜')
    parser.add_argument('--density', type=float, default=0.02, help='H í–‰ë ¬ ë°€ë„')
    parser.add_argument('--output_dir', type=str, default='data', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    generate_phase2_test_data(
        n_firms=args.n_firms,
        density=args.density,
        output_dir=args.output_dir
    )
