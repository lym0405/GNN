"""
Phase 3: Link Prediction Benchmarking (MAIN - Full Training)
=============================================================
ë§í¬ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (ì „ì²´ í•™ìŠµ)

ì‹¤í–‰ ë°©ë²•:
    python main_phase3.py
"""

import sys
import os
from pathlib import Path
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from src.link_predictor import MLPLinkPredictor
from src.phase3_trainer import LinkPredictionTrainer, prepare_dataloader
from src.metrics import evaluate_link_prediction, convert_torch_to_numpy

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================
# ì„¤ì • (Config)
# ============================================================

class Config:
    """Phase 3 ì „ì²´ í•™ìŠµ ì„¤ì •"""
    
    # ë°ì´í„° ê²½ë¡œ
    DATA_DIR = Path("data")
    OUTPUT_DIR = DATA_DIR / "processed"
    RESULTS_DIR = Path("results")
    
    # ì…ë ¥ íŒŒì¼
    NODE_EMBEDDINGS = OUTPUT_DIR / "node_embeddings_static.pt"
    TRAIN_EDGES = OUTPUT_DIR / "train_edges.npy"
    TEST_EDGES = OUTPUT_DIR / "test_edges.npy"
    
    # ì¶œë ¥ íŒŒì¼
    MODEL_SAVE_PATH = RESULTS_DIR / "link_predictor_best.pt"
    METRICS_SAVE_PATH = RESULTS_DIR / "phase3_metrics.npz"
    
    # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    HIDDEN_DIMS = [128, 64, 32]  # ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬
    DROPOUT = 0.3
    AGGREGATION = 'concat'  # 'concat', 'hadamard', 'mean', 'abs_diff'
    
    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    EPOCHS = 100
    BATCH_SIZE = 2048
    LEARNING_RATE = 0.001
    WEIGHT_DECAY = 1e-5
    EARLY_STOPPING_PATIENCE = 15
    
    # ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§
    NEG_SAMPLING_RATIO = 1.0  # Positive : Negative = 1:1
    
    # í‰ê°€ ì„¤ì •
    EVAL_THRESHOLD = 0.5
    TOPK_LIST = [10, 50, 100, 500]
    
    # Device
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'


# ============================================================
# ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§
# ============================================================

def sample_negative_edges(
    num_nodes: int,
    positive_edges: torch.Tensor,
    num_negatives: int,
    seed: int = 42
) -> torch.Tensor:
    """
    ë„¤ê±°í‹°ë¸Œ ì—£ì§€ ìƒ˜í”Œë§
    
    Parameters
    ----------
    num_nodes : int
    positive_edges : torch.Tensor [2, E]
    num_negatives : int
    seed : int
    
    Returns
    -------
    negative_edges : torch.Tensor [2, num_negatives]
    """
    logger.info(f"ğŸ² ë„¤ê±°í‹°ë¸Œ ì—£ì§€ ìƒ˜í”Œë§: {num_negatives:,}ê°œ")
    
    np.random.seed(seed)
    
    # Positive ì—£ì§€ë¥¼ setìœ¼ë¡œ ë³€í™˜ (ë¹ ë¥¸ ê²€ìƒ‰)
    pos_set = set(map(tuple, positive_edges.t().numpy()))
    
    negative_edges = []
    attempts = 0
    max_attempts = num_negatives * 10
    
    while len(negative_edges) < num_negatives and attempts < max_attempts:
        # ëœë¤ ì—£ì§€ ìƒì„±
        u = np.random.randint(0, num_nodes, size=num_negatives * 2)
        v = np.random.randint(0, num_nodes, size=num_negatives * 2)
        
        # Self-loop ì œê±° & Positive ì œê±°
        for i in range(len(u)):
            if u[i] != v[i] and (u[i], v[i]) not in pos_set:
                negative_edges.append([u[i], v[i]])
                if len(negative_edges) >= num_negatives:
                    break
        
        attempts += 1
    
    negative_edges = torch.tensor(negative_edges[:num_negatives]).t()
    logger.info(f"   âœ“ ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§ ì™„ë£Œ: {negative_edges.shape[1]:,}ê°œ")
    
    return negative_edges


def prepare_train_val_data(
    train_edges: torch.Tensor,
    num_nodes: int,
    neg_ratio: float = 1.0,
    val_ratio: float = 0.2,
    seed: int = 42
):
    """
    Train/Val ë°ì´í„° ì¤€ë¹„ (Positive + Negative)
    
    Returns
    -------
    train_edge_index : torch.Tensor [2, E_train]
    train_labels : torch.Tensor [E_train]
    val_edge_index : torch.Tensor [2, E_val]
    val_labels : torch.Tensor [E_val]
    """
    logger.info("\n[ë°ì´í„° ì¤€ë¹„] Train/Val ë¶„í• ")
    
    # Train/Val ë¶„í• 
    num_edges = train_edges.shape[1]
    num_val = int(num_edges * val_ratio)
    num_train = num_edges - num_val
    
    np.random.seed(seed)
    indices = np.random.permutation(num_edges)
    
    train_pos_edges = train_edges[:, indices[:num_train]]
    val_pos_edges = train_edges[:, indices[num_train:]]
    
    logger.info(f"   âœ“ Train Positive: {train_pos_edges.shape[1]:,}")
    logger.info(f"   âœ“ Val Positive: {val_pos_edges.shape[1]:,}")
    
    # ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§
    num_train_neg = int(train_pos_edges.shape[1] * neg_ratio)
    num_val_neg = int(val_pos_edges.shape[1] * neg_ratio)
    
    train_neg_edges = sample_negative_edges(
        num_nodes, train_edges, num_train_neg, seed=seed
    )
    val_neg_edges = sample_negative_edges(
        num_nodes, train_edges, num_val_neg, seed=seed + 1
    )
    
    # Train ë°ì´í„° ê²°í•©
    train_edge_index = torch.cat([train_pos_edges, train_neg_edges], dim=1)
    train_labels = torch.cat([
        torch.ones(train_pos_edges.shape[1]),
        torch.zeros(train_neg_edges.shape[1])
    ])
    
    # Val ë°ì´í„° ê²°í•©
    val_edge_index = torch.cat([val_pos_edges, val_neg_edges], dim=1)
    val_labels = torch.cat([
        torch.ones(val_pos_edges.shape[1]),
        torch.zeros(val_neg_edges.shape[1])
    ])
    
    logger.info(f"   âœ“ Train Total: {train_edge_index.shape[1]:,} (Pos/Neg: {train_pos_edges.shape[1]:,}/{train_neg_edges.shape[1]:,})")
    logger.info(f"   âœ“ Val Total: {val_edge_index.shape[1]:,} (Pos/Neg: {val_pos_edges.shape[1]:,}/{val_neg_edges.shape[1]:,})")
    
    return train_edge_index, train_labels, val_edge_index, val_labels


def prepare_test_data(
    test_edges: torch.Tensor,
    num_nodes: int,
    train_edges: torch.Tensor,
    neg_ratio: float = 1.0,
    seed: int = 42
):
    """
    Test ë°ì´í„° ì¤€ë¹„ (Positive + Negative)
    
    Returns
    -------
    test_edge_index : torch.Tensor [2, E_test]
    test_labels : torch.Tensor [E_test]
    """
    logger.info("\n[ë°ì´í„° ì¤€ë¹„] Test ë°ì´í„°")
    
    num_test_pos = test_edges.shape[1]
    num_test_neg = int(num_test_pos * neg_ratio)
    
    logger.info(f"   âœ“ Test Positive: {num_test_pos:,}")
    
    # ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§ (Train ì—£ì§€ë„ ì œì™¸)
    all_pos_edges = torch.cat([train_edges, test_edges], dim=1)
    test_neg_edges = sample_negative_edges(
        num_nodes, all_pos_edges, num_test_neg, seed=seed + 2
    )
    
    # Test ë°ì´í„° ê²°í•©
    test_edge_index = torch.cat([test_edges, test_neg_edges], dim=1)
    test_labels = torch.cat([
        torch.ones(num_test_pos),
        torch.zeros(num_test_neg)
    ])
    
    logger.info(f"   âœ“ Test Total: {test_edge_index.shape[1]:,} (Pos/Neg: {num_test_pos:,}/{num_test_neg:,})")
    
    return test_edge_index, test_labels


# ============================================================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ============================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    config = Config()
    
    print("\n" + "=" * 70)
    print("ğŸš€ Phase 3: Link Prediction (FULL TRAINING)")
    print("=" * 70)
    print(f"Device: {config.DEVICE}")
    print(f"Epochs: {config.EPOCHS}")
    print(f"Batch Size: {config.BATCH_SIZE}")
    print(f"Hidden Dims: {config.HIDDEN_DIMS}")
    print("=" * 70)
    
    try:
        # ============================================================
        # 1. ë°ì´í„° ë¡œë“œ
        # ============================================================
        
        logger.info("\n[Step 1] ë°ì´í„° ë¡œë“œ")
        
        # ì„ë² ë”© ë¡œë“œ
        embeddings = torch.load(config.NODE_EMBEDDINGS)
        num_nodes = embeddings.shape[0]
        emb_dim = embeddings.shape[1]
        
        logger.info(f"âœ… ì„ë² ë”© ë¡œë“œ: {embeddings.shape}")
        
        # ì—£ì§€ ë¡œë“œ
        train_edges = torch.from_numpy(np.load(config.TRAIN_EDGES))
        test_edges = torch.from_numpy(np.load(config.TEST_EDGES))
        
        logger.info(f"âœ… Train ì—£ì§€: {train_edges.shape[1]:,}")
        logger.info(f"âœ… Test ì—£ì§€: {test_edges.shape[1]:,}")
        
        # ============================================================
        # 2. Train/Val/Test ë°ì´í„° ì¤€ë¹„
        # ============================================================
        
        train_edge_index, train_labels, val_edge_index, val_labels = \
            prepare_train_val_data(
                train_edges, num_nodes, config.NEG_SAMPLING_RATIO,
                val_ratio=0.2, seed=42
            )
        
        test_edge_index, test_labels = prepare_test_data(
            test_edges, num_nodes, train_edges,
            config.NEG_SAMPLING_RATIO, seed=42
        )
        
        # DataLoader ìƒì„±
        train_loader = prepare_dataloader(
            train_edge_index, train_labels, config.BATCH_SIZE, shuffle=True
        )
        val_loader = prepare_dataloader(
            val_edge_index, val_labels, config.BATCH_SIZE, shuffle=False
        )
        test_loader = prepare_dataloader(
            test_edge_index, test_labels, config.BATCH_SIZE, shuffle=False
        )
        
        # ============================================================
        # 3. ëª¨ë¸ ì´ˆê¸°í™”
        # ============================================================
        
        logger.info("\n[Step 3] ëª¨ë¸ ì´ˆê¸°í™”")
        
        model = MLPLinkPredictor(
            input_dim=emb_dim,
            hidden_dims=config.HIDDEN_DIMS,
            dropout=config.DROPOUT,
            aggregation=config.AGGREGATION
        )
        
        optimizer = optim.Adam(
            model.parameters(),
            lr=config.LEARNING_RATE,
            weight_decay=config.WEIGHT_DECAY
        )
        
        criterion = nn.BCEWithLogitsLoss()
        
        logger.info(f"âœ… MLPLinkPredictor")
        logger.info(f"   - ì…ë ¥ ì°¨ì›: {emb_dim}")
        logger.info(f"   - ì€ë‹‰ ì°¨ì›: {config.HIDDEN_DIMS}")
        logger.info(f"   - Aggregation: {config.AGGREGATION}")
        logger.info(f"   - íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}")
        
        # ============================================================
        # 4. í•™ìŠµ
        # ============================================================
        
        logger.info("\n[Step 4] í•™ìŠµ ì‹œì‘")
        
        trainer = LinkPredictionTrainer(
            model=model,
            optimizer=optimizer,
            criterion=criterion,
            device=config.DEVICE
        )
        
        trainer.train(
            train_loader=train_loader,
            val_loader=val_loader,
            embeddings=embeddings,
            epochs=config.EPOCHS,
            early_stopping_patience=config.EARLY_STOPPING_PATIENCE,
            verbose=True
        )
        
        # ============================================================
        # 5. ëª¨ë¸ ì €ì¥
        # ============================================================
        
        config.RESULTS_DIR.mkdir(parents=True, exist_ok=True)
        torch.save(model.state_dict(), config.MODEL_SAVE_PATH)
        logger.info(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥: {config.MODEL_SAVE_PATH}")
        
        # ============================================================
        # 6. Test í‰ê°€
        # ============================================================
        
        logger.info("\n[Step 6] Test í‰ê°€")
        
        test_scores = trainer.predict(
            test_edge_index, embeddings, batch_size=config.BATCH_SIZE
        )
        
        test_labels_np = test_labels.numpy()
        
        # ì¢…í•© í‰ê°€
        test_metrics = evaluate_link_prediction(
            y_true=test_labels_np,
            y_score=test_scores,
            threshold=config.EVAL_THRESHOLD,
            k_list=config.TOPK_LIST,
            verbose=True
        )
        
        # ============================================================
        # 7. ê²°ê³¼ ì €ì¥
        # ============================================================
        
        logger.info("\n[Step 7] ê²°ê³¼ ì €ì¥")
        
        np.savez(
            config.METRICS_SAVE_PATH,
            test_scores=test_scores,
            test_labels=test_labels_np,
            test_metrics=test_metrics,
            train_losses=trainer.train_losses,
            val_losses=trainer.val_losses,
            val_accs=trainer.val_accs
        )
        
        logger.info(f"ğŸ’¾ ë©”íŠ¸ë¦­ ì €ì¥: {config.METRICS_SAVE_PATH}")
        
        # ============================================================
        # 8. ì™„ë£Œ
        # ============================================================
        
        print("\n" + "=" * 70)
        print("âœ… Phase 3 ì™„ë£Œ!")
        print("=" * 70)
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼:")
        print(f"   - {config.MODEL_SAVE_PATH}")
        print(f"   - {config.METRICS_SAVE_PATH}")
        print("=" * 70)
        print(f"\nğŸ“Š ìµœì¢… Test ì„±ëŠ¥:")
        print(f"   - Accuracy:  {test_metrics['accuracy']:.4f}")
        print(f"   - Precision: {test_metrics['precision']:.4f}")
        print(f"   - Recall:    {test_metrics['recall']:.4f}")
        print(f"   - F1 Score:  {test_metrics['f1']:.4f}")
        print(f"   - AUC-ROC:   {test_metrics.get('auc_roc', 0):.4f}")
        print("=" * 70)
        
    except FileNotFoundError as e:
        logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        logger.info("\nğŸ’¡ TIP: Phase 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”:")
        logger.info("   python main_phase2.py")
        sys.exit(1)
    
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
