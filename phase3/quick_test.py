"""
Phase 3: Two-Track Hybrid Link Predict    # ë°ì´í„° ê²½ë¡œ (í˜„ì¬ íŒŒì¼ ê¸°ì¤€)
    SCRIPT_DIR = Path(__file__).parent
    DATA_DIR = SCRIPT_DIR.parent / "data"
    OUTPUT_DIR = DATA_DIR / "processed"
    RESULTS_DIR = SCRIPT_DIR.parent / "results" / "quick_test"(QUICK TEST)
======================================================
ë””ë²„ê¹…ìš© ì§§ì€ ì—í­ í…ŒìŠ¤íŠ¸

ì‹¤í–‰ ë°©ë²•:
    python quick_test_phase3.py
"""

import sys
import os
from pathlib import Path
import numpy as np
import torch
import torch.optim as optim
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from phase3.src.temporal_graph_builder import TemporalGraphBuilder
from phase3.src.sc_tgn import SC_TGN
from phase3.src.graphseal import GraphSEAL, HybridLinkPredictor
from phase3.src.hybrid_trainer import HybridTrainer
from phase3.src.negative_sampler import prepare_events_with_negatives

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================
# ì„¤ì • (Config) - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
# ============================================================

class QuickConfig:
    """Phase 3 ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì„¤ì • (ì‘ì€ ëª¨ë¸, ì ì€ ì—í­)"""
    
    # ë°ì´í„° ê²½ë¡œ (í˜„ì¬ íŒŒì¼ ê¸°ì¤€)
    SCRIPT_DIR = Path(__file__).parent
    DATA_DIR = SCRIPT_DIR.parent / "data"
    OUTPUT_DIR = DATA_DIR / "processed"
    RESULTS_DIR = SCRIPT_DIR.parent / "results" / "quick_test"
    
    # ì…ë ¥ íŒŒì¼
    NODE_EMBEDDINGS = OUTPUT_DIR / "node_embeddings_static.pt"
    TRAIN_EDGES = OUTPUT_DIR / "train_edges.npy"
    TEST_EDGES = OUTPUT_DIR / "test_edges.npy"
    TIS_SCORES = OUTPUT_DIR / "tis_score_normalized.npy"
    
    # ì¶œë ¥ íŒŒì¼
    MODEL_SAVE_PATH = RESULTS_DIR / "hybrid_model_quick.pt"
    METRICS_SAVE_PATH = RESULTS_DIR / "phase3_metrics_quick.npz"
    
    # Track A (SC-TGN) - ì‘ì€ ëª¨ë¸
    TGN_MEMORY_DIM = 64
    TGN_TIME_DIM = 16
    TGN_MESSAGE_DIM = 64
    TGN_EMBEDDING_DIM = 32
    
    # Track B (GraphSEAL) - ì‘ì€ ëª¨ë¸
    GRAPHSEAL_HIDDEN_DIM = 64
    GRAPHSEAL_NUM_HOPS = 1  # 1-hopë§Œ
    USE_UKGE = True
    
    # Ensemble
    ENSEMBLE_ALPHA = 0.5
    
    # Loss ì„¤ì •
    LOSS_ALPHA = 0.3  # TIS í˜ë„í‹° ê°•ë„
    SOFT_NEGATIVE = 0.0  # Negative ì—£ì§€ soft label
    RANKING_WEIGHT = 0.1  # Ranking loss ê°€ì¤‘ì¹˜
    
    # Negative Sampling
    HISTORICAL_RATIO = 0.5  # Historical negatives ë¹„ìœ¨
    NEG_RATIO = 0.5  # Positive 1ê°œë‹¹ Negative ê°œìˆ˜ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)
    
    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
    EPOCHS = 5  # ì§§ê²Œ!
    BATCH_SIZE = 512
    LEARNING_RATE = 0.001
    WEIGHT_DECAY = 1e-5
    EARLY_STOPPING_PATIENCE = 3
    
    # í‰ê°€ ì„¤ì •
    RECALL_K_LIST = [10, 50, 100]
    
    # Device
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'


# ============================================================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ============================================================

def main():
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""
    config = QuickConfig()
    
    print("\n" + "=" * 70)
    print("ğŸš€ Phase 3: Quick Test (5 Epochs)")
    print("=" * 70)
    print(f"Device: {config.DEVICE}")
    print(f"Epochs: {config.EPOCHS} (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)")
    print(f"Track A: SC-TGN (ì‘ì€ ëª¨ë¸)")
    print(f"Track B: GraphSEAL (ì‘ì€ ëª¨ë¸)")
    print("=" * 70)
    
    try:
        # ============================================================
        # 1. ì‹œê³„ì—´ ë°ì´í„° ë¡œë“œ
        # ============================================================
        
        logger.info("\n[Step 1] ì‹œê³„ì—´ ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ")
        
        builder = TemporalGraphBuilder(data_dir=str(config.DATA_DIR))
        temporal_data = builder.build_temporal_data(train_ratio=0.8)
        
        events = temporal_data['events']
        num_nodes = temporal_data['num_nodes']
        train_mask = temporal_data['train_mask']
        test_mask = temporal_data['test_mask']
        node_features = temporal_data['node_features']
        
        logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        
        # ============================================================
        # 2. Static Embeddings ë¡œë“œ
        # ============================================================
        
        logger.info("\n[Step 2] Static Embeddings ë¡œë“œ")
        
        node_embeddings = torch.load(config.NODE_EMBEDDINGS)
        train_edges = torch.from_numpy(np.load(config.TRAIN_EDGES))
        
        tis_scores = None
        if config.TIS_SCORES.exists():
            tis_scores = torch.from_numpy(np.load(config.TIS_SCORES)).float()
        
        logger.info(f"âœ… ë¡œë“œ ì™„ë£Œ")
        
        # ============================================================
        # 3. Train/Val ë¶„í• 
        # ============================================================
        
        logger.info("\n[Step 3] Train/Val ë¶„í• ")
        
        train_indices = np.where(train_mask)[0]
        np.random.shuffle(train_indices)
        
        val_size = int(len(train_indices) * 0.2)
        val_indices = train_indices[:val_size]
        train_indices = train_indices[val_size:]
        
        train_mask_final = np.zeros(len(events), dtype=bool)
        val_mask_final = np.zeros(len(events), dtype=bool)
        train_mask_final[train_indices] = True
        val_mask_final[val_indices] = True
        
        logger.info(f"   âœ“ ë¶„í•  ì™„ë£Œ")
        
        # ============================================================
        # 4. ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§ (Historical + Random)
        # ============================================================
        
        logger.info("\n[Step 4] ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§ (Historical + Random)")
        
        train_events = prepare_events_with_negatives(
            events=events,
            mask=train_mask_final,
            num_nodes=num_nodes,
            current_edges=train_edges,
            data_dir=str(config.DATA_DIR),
            historical_ratio=config.HISTORICAL_RATIO,
            neg_ratio=config.NEG_RATIO,
            seed=42
        )
        
        val_events = prepare_events_with_negatives(
            events=events,
            mask=val_mask_final,
            num_nodes=num_nodes,
            current_edges=train_edges,
            data_dir=str(config.DATA_DIR),
            historical_ratio=config.HISTORICAL_RATIO,
            neg_ratio=config.NEG_RATIO,
            seed=43
        )
        
        test_events = prepare_events_with_negatives(
            events=events,
            mask=test_mask,
            num_nodes=num_nodes,
            current_edges=train_edges,
            data_dir=str(config.DATA_DIR),
            historical_ratio=config.HISTORICAL_RATIO,
            neg_ratio=config.NEG_RATIO,
            seed=44
        )
        
        # ============================================================
        # 5. ì‘ì€ ëª¨ë¸ ì´ˆê¸°í™”
        # ============================================================
        
        logger.info("\n[Step 5] ì‘ì€ ëª¨ë¸ ì´ˆê¸°í™”")
        
        # Track A: SC-TGN (ì‘ì€ ë²„ì „)
        tgn_model = SC_TGN(
            num_nodes=num_nodes,
            node_dim=node_features.shape[1],
            edge_dim=2,
            memory_dim=config.TGN_MEMORY_DIM,
            time_dim=config.TGN_TIME_DIM,
            message_dim=config.TGN_MESSAGE_DIM,
            embedding_dim=config.TGN_EMBEDDING_DIM
        )
        
        # Track B: GraphSEAL (ì‘ì€ ë²„ì „)
        graphseal_model = GraphSEAL(
            embedding_dim=node_embeddings.shape[1],
            hidden_dim=config.GRAPHSEAL_HIDDEN_DIM,
            num_hops=config.GRAPHSEAL_NUM_HOPS,
            use_ukge=config.USE_UKGE
        )
        
        # Hybrid
        hybrid_model = HybridLinkPredictor(
            tgn_model=tgn_model,
            graphseal_model=graphseal_model,
            alpha=config.ENSEMBLE_ALPHA
        )
        
        logger.info(f"âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ (ì´ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in hybrid_model.parameters()):,})")
        
        # ============================================================
        # 6. ë¹ ë¥¸ í•™ìŠµ
        # ============================================================
        
        logger.info("\n[Step 6] ë¹ ë¥¸ í•™ìŠµ (5 epochs)")
        
        optimizer = optim.Adam(
            hybrid_model.parameters(),
            lr=config.LEARNING_RATE,
            weight_decay=config.WEIGHT_DECAY
        )
        
        trainer = HybridTrainer(
            hybrid_model=hybrid_model,
            optimizer=optimizer,
            device=config.DEVICE,
            loss_alpha=config.LOSS_ALPHA,
            soft_negative=config.SOFT_NEGATIVE,
            ranking_weight=config.RANKING_WEIGHT
        )
        
        trainer.train(
            train_events=train_events,
            val_events=val_events,
            node_features=node_features,
            node_embeddings=node_embeddings,
            train_edge_index=train_edges,
            tis_scores=tis_scores,
            epochs=config.EPOCHS,
            batch_size=config.BATCH_SIZE,
            early_stopping_patience=config.EARLY_STOPPING_PATIENCE,
            k_list=config.RECALL_K_LIST,
            verbose=True
        )
        
        # ============================================================
        # 7. ì €ì¥
        # ============================================================
        
        config.RESULTS_DIR.mkdir(parents=True, exist_ok=True)
        torch.save(hybrid_model.state_dict(), config.MODEL_SAVE_PATH)
        logger.info(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥: {config.MODEL_SAVE_PATH}")
        
        # ============================================================
        # 8. Test í‰ê°€
        # ============================================================
        
        logger.info("\n[Step 8] Test í‰ê°€")
        
        hybrid_model.tgn.reset_memory()
        
        test_metrics = trainer.evaluate(
            events=test_events,
            node_features=node_features,
            node_embeddings=node_embeddings,
            edge_index=train_edges,
            tis_scores=tis_scores,
            k_list=config.RECALL_K_LIST,
            batch_size=config.BATCH_SIZE * 2
        )
        
        # ============================================================
        # 9. ê²°ê³¼ ì €ì¥
        # ============================================================
        
        np.savez(
            config.METRICS_SAVE_PATH,
            test_metrics=test_metrics,
            train_losses=trainer.train_losses,
            val_losses=trainer.val_losses,
            val_recalls=trainer.val_recalls
        )
        
        logger.info(f"ğŸ’¾ ë©”íŠ¸ë¦­ ì €ì¥: {config.METRICS_SAVE_PATH}")
        
        # ============================================================
        # 10. ì™„ë£Œ
        # ============================================================
        
        print("\n" + "=" * 70)
        print("âœ… Quick Test ì™„ë£Œ!")
        print("=" * 70)
        print(f"\nğŸ“Š Test ì„±ëŠ¥ (Recall@K):")
        for k in config.RECALL_K_LIST:
            print(f"   - Recall@{k}: {test_metrics[f'recall@{k}']:.4f}")
        print("=" * 70)
        print("\në‹¤ìŒ ë‹¨ê³„:")
        print("  python main_phase3_hybrid.py  # ì „ì²´ í•™ìŠµ (100 epochs)")
        print("=" * 70)
        
    except FileNotFoundError as e:
        logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        logger.info("\nğŸ’¡ TIP: Phase 1, 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
        sys.exit(1)
    
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
