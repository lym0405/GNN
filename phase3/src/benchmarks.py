"""
Phase 3: Benchmark Heuristic Algorithms
========================================
ê³ ì „ì  ë§í¬ ì˜ˆì¸¡ íœ´ë¦¬ìŠ¤í‹± ì•Œê³ ë¦¬ì¦˜:
    1. PA (Preferential Attachment)
    2. RA (Resource Allocation)
    3. JC (Jaccard Coefficient)
"""

import numpy as np
import torch
from typing import Tuple, Dict
import logging
from collections import defaultdict

logger = logging.getLogger(__name__)


class LinkPredictionBenchmarks:
    """
    ë§í¬ ì˜ˆì¸¡ ë²¤ì¹˜ë§ˆí¬ íœ´ë¦¬ìŠ¤í‹± ì•Œê³ ë¦¬ì¦˜
    
    Parameters
    ----------
    edge_index : torch.Tensor [2, E]
        í•™ìŠµ ê·¸ë˜í”„ì˜ ì—£ì§€ ì¸ë±ìŠ¤
    num_nodes : int
        ì „ì²´ ë…¸ë“œ ìˆ˜
    """
    
    def __init__(self, edge_index: torch.Tensor, num_nodes: int):
        self.edge_index = edge_index.numpy()
        self.num_nodes = num_nodes
        
        # ì¸ì ‘ ë¦¬ìŠ¤íŠ¸ êµ¬ì¶•
        self.adjacency = defaultdict(set)
        for i in range(self.edge_index.shape[1]):
            src = self.edge_index[0, i]
            dst = self.edge_index[1, i]
            self.adjacency[src].add(dst)
            # ë¬´ë°©í–¥ ê·¸ë˜í”„ë¡œ ì·¨ê¸‰
            self.adjacency[dst].add(src)
        
        # Degree ê³„ì‚°
        self.degrees = {node: len(neighbors) for node, neighbors in self.adjacency.items()}
        
        logger.info(f"âœ… Benchmarks ì´ˆê¸°í™”")
        logger.info(f"   - ë…¸ë“œ ìˆ˜: {num_nodes}")
        logger.info(f"   - ì—£ì§€ ìˆ˜: {self.edge_index.shape[1]:,}")
        logger.info(f"   - í‰ê·  Degree: {np.mean(list(self.degrees.values())):.2f}")
    
    def preferential_attachment(
        self,
        src_nodes: torch.Tensor,
        dst_nodes: torch.Tensor
    ) -> np.ndarray:
        """
        PA (Preferential Attachment)
        
        Score(u, v) = degree(u) * degree(v)
        
        Parameters
        ----------
        src_nodes : torch.Tensor [N]
        dst_nodes : torch.Tensor [N]
        
        Returns
        -------
        scores : np.ndarray [N]
        """
        src_nodes = src_nodes.numpy()
        dst_nodes = dst_nodes.numpy()
        
        scores = []
        for src, dst in zip(src_nodes, dst_nodes):
            deg_u = self.degrees.get(src, 0)
            deg_v = self.degrees.get(dst, 0)
            scores.append(deg_u * deg_v)
        
        return np.array(scores, dtype=np.float32)
    
    def resource_allocation(
        self,
        src_nodes: torch.Tensor,
        dst_nodes: torch.Tensor
    ) -> np.ndarray:
        """
        RA (Resource Allocation)
        
        Score(u, v) = Î£_{z âˆˆ common_neighbors} 1 / degree(z)
        
        ê³µí†µ ì´ì›ƒì´ ë§ì„ìˆ˜ë¡, ê·¸ ì´ì›ƒì˜ degreeê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        
        Parameters
        ----------
        src_nodes : torch.Tensor [N]
        dst_nodes : torch.Tensor [N]
        
        Returns
        -------
        scores : np.ndarray [N]
        """
        src_nodes = src_nodes.numpy()
        dst_nodes = dst_nodes.numpy()
        
        scores = []
        for src, dst in zip(src_nodes, dst_nodes):
            neighbors_u = self.adjacency.get(src, set())
            neighbors_v = self.adjacency.get(dst, set())
            
            # ê³µí†µ ì´ì›ƒ
            common = neighbors_u & neighbors_v
            
            if len(common) == 0:
                scores.append(0.0)
            else:
                # Resource Allocation: 1 / degree(z) í•©ì‚°
                score = sum(1.0 / self.degrees.get(z, 1) for z in common)
                scores.append(score)
        
        return np.array(scores, dtype=np.float32)
    
    def jaccard_coefficient(
        self,
        src_nodes: torch.Tensor,
        dst_nodes: torch.Tensor
    ) -> np.ndarray:
        """
        JC (Jaccard Coefficient)
        
        Score(u, v) = |common_neighbors| / |union_neighbors|
        
        ë‘ ë…¸ë“œì˜ ì´ì›ƒ ì§‘í•©ì´ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ëŠ”ê°€ (ìœ ì‚¬ë„)
        
        Parameters
        ----------
        src_nodes : torch.Tensor [N]
        dst_nodes : torch.Tensor [N]
        
        Returns
        -------
        scores : np.ndarray [N]
        """
        src_nodes = src_nodes.numpy()
        dst_nodes = dst_nodes.numpy()
        
        scores = []
        for src, dst in zip(src_nodes, dst_nodes):
            neighbors_u = self.adjacency.get(src, set())
            neighbors_v = self.adjacency.get(dst, set())
            
            # ê³µí†µ ì´ì›ƒ & í•©ì§‘í•©
            common = neighbors_u & neighbors_v
            union = neighbors_u | neighbors_v
            
            if len(union) == 0:
                scores.append(0.0)
            else:
                # Jaccard: êµì§‘í•© / í•©ì§‘í•©
                score = len(common) / len(union)
                scores.append(score)
        
        return np.array(scores, dtype=np.float32)
    
    def compute_all_benchmarks(
        self,
        src_nodes: torch.Tensor,
        dst_nodes: torch.Tensor
    ) -> Dict[str, np.ndarray]:
        """
        ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì•Œê³ ë¦¬ì¦˜ ì ìˆ˜ ê³„ì‚°
        
        Returns
        -------
        scores : Dict[str, np.ndarray]
            {
                'PA': scores_pa,
                'RA': scores_ra,
                'JC': scores_jc
            }
        """
        logger.info(f"ğŸ” ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ ê³„ì‚° ì¤‘... ({len(src_nodes):,}ê°œ ì—£ì§€)")
        
        scores = {
            'PA': self.preferential_attachment(src_nodes, dst_nodes),
            'RA': self.resource_allocation(src_nodes, dst_nodes),
            'JC': self.jaccard_coefficient(src_nodes, dst_nodes)
        }
        
        logger.info(f"âœ… ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ")
        
        return scores


# ============================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================

def evaluate_benchmarks(
    edge_index: torch.Tensor,
    num_nodes: int,
    test_pos_edges: torch.Tensor,
    test_neg_edges: torch.Tensor,
    k_list: list = [10, 50, 100]
) -> Dict[str, Dict[str, float]]:
    """
    ë²¤ì¹˜ë§ˆí¬ ì•Œê³ ë¦¬ì¦˜ í‰ê°€
    
    Parameters
    ----------
    edge_index : torch.Tensor [2, E]
        í•™ìŠµ ê·¸ë˜í”„
    num_nodes : int
    test_pos_edges : torch.Tensor [2, E_pos]
    test_neg_edges : torch.Tensor [2, E_neg]
    k_list : list
    
    Returns
    -------
    results : Dict[str, Dict[str, float]]
        {
            'PA': {'recall@10': 0.3, 'recall@50': 0.5, ...},
            'RA': {...},
            'JC': {...}
        }
    """
    logger.info("\n" + "=" * 70)
    logger.info("ğŸ” ë²¤ì¹˜ë§ˆí¬ ì•Œê³ ë¦¬ì¦˜ í‰ê°€")
    logger.info("=" * 70)
    
    # ë²¤ì¹˜ë§ˆí¬ ì´ˆê¸°í™”
    benchmarks = LinkPredictionBenchmarks(edge_index, num_nodes)
    
    # Test ì—£ì§€
    src_test = torch.cat([test_pos_edges[0], test_neg_edges[0]])
    dst_test = torch.cat([test_pos_edges[1], test_neg_edges[1]])
    labels = torch.cat([
        torch.ones(test_pos_edges.shape[1]),
        torch.zeros(test_neg_edges.shape[1])
    ]).numpy()
    
    # ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜
    all_scores = benchmarks.compute_all_benchmarks(src_test, dst_test)
    
    # ê° ì•Œê³ ë¦¬ì¦˜ë³„ í‰ê°€
    results = {}
    
    for method_name, scores in all_scores.items():
        method_results = {}
        
        # Recall@K
        for k in k_list:
            # ìƒìœ„ Kê°œ ì¸ë±ìŠ¤
            top_k_indices = np.argsort(scores)[::-1][:k]
            top_k_labels = labels[top_k_indices]
            
            # Recall@K
            recall_k = top_k_labels.sum() / labels.sum()
            method_results[f'recall@{k}'] = recall_k
        
        # MRR (Mean Reciprocal Rank)
        # Positive ì—£ì§€ë“¤ì˜ ë­í‚¹ ìœ„ì¹˜
        pos_indices = np.where(labels == 1)[0]
        
        # ì ìˆ˜ ê¸°ì¤€ ë­í‚¹ (ë‚´ë¦¼ì°¨ìˆœ)
        ranking = np.argsort(scores)[::-1]
        rank_dict = {idx: rank + 1 for rank, idx in enumerate(ranking)}
        
        # Positive ì—£ì§€ë“¤ì˜ rank
        pos_ranks = [rank_dict[idx] for idx in pos_indices]
        
        # Reciprocal Rank
        reciprocal_ranks = [1.0 / rank for rank in pos_ranks]
        mrr = np.mean(reciprocal_ranks)
        method_results['MRR'] = mrr
        
        results[method_name] = method_results
        
        logger.info(f"\nğŸ“Š {method_name} ê²°ê³¼:")
        for metric, value in method_results.items():
            logger.info(f"   - {metric}: {value:.4f}")
    
    logger.info("=" * 70)
    
    return results
