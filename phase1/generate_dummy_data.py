"""
Dummy Data Generator for Phase 1 Testing
==========================================
Phase 1ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ë”ë¯¸ ë°ì´í„° ìƒì„±

ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ë•Œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¬ìš©
"""

import numpy as np
import pandas as pd
from scipy.sparse import random, save_npz
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def generate_dummy_data(
    n_firms: int = 10000,
    density: float = 0.01,
    output_dir: str = "../data/raw"
):
    """
    ë”ë¯¸ ë°ì´í„° ìƒì„±
    
    Parameters
    ----------
    n_firms : int
        ê¸°ì—… ìˆ˜
    density : float
        H í–‰ë ¬ ë°€ë„
    output_dir : str
        ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"ğŸ² ë”ë¯¸ ë°ì´í„° ìƒì„± ì‹œì‘ (N={n_firms})")
    
    # 1. IO í…Œì´ë¸” (33Ã—33)
    logger.info("1ï¸âƒ£ IO í…Œì´ë¸” ìƒì„±...")
    A_matrix = np.random.rand(33, 33).astype(np.float32)
    A_matrix = A_matrix / A_matrix.sum(axis=1, keepdims=True)  # í–‰ í•© = 1
    
    sector_names = [f'sector_{i:02d}' for i in range(1, 34)]
    A_df = pd.DataFrame(A_matrix, index=sector_names, columns=sector_names)
    A_df.to_csv(output_path / "A_33.csv")
    logger.info(f"   âœ“ A_33.csv ì €ì¥")
    
    # 2. H í–‰ë ¬ (ê±°ë˜ ë„¤íŠ¸ì›Œí¬, Sparse)
    logger.info("2ï¸âƒ£ H í–‰ë ¬ ìƒì„±...")
    H_matrix = random(n_firms, n_firms, density=density, format='csr', random_state=42)
    H_matrix = H_matrix * 1e9  # ê±°ë˜ ê¸ˆì•¡ (ì›)
    save_npz(output_path / "H_csr_model2.npz", H_matrix)
    logger.info(f"   âœ“ H_csr_model2.npz ì €ì¥ (ë°€ë„: {density*100:.2f}%)")
    
    # 3. ê¸°ì—… ì¸ë±ìŠ¤ ë§¤í•‘
    logger.info("3ï¸âƒ£ ê¸°ì—… ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„±...")
    firm_ids = [f'firm_{i:06d}' for i in range(n_firms)]
    firm_to_idx = pd.DataFrame({
        'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': firm_ids,
        'idx': range(n_firms)
    })
    firm_to_idx.to_csv(output_path / "firm_to_idx_model2.csv", index=False)
    logger.info(f"   âœ“ firm_to_idx_model2.csv ì €ì¥")
    
    # 4. ê¸°ì—… ì •ë³´ (ì‚°ì—…ì½”ë“œ í¬í•¨)
    logger.info("4ï¸âƒ£ ê¸°ì—… ì •ë³´ ìƒì„±...")
    
    # ì‚°ì—…ì½”ë“œ: 1~33 ëœë¤ í• ë‹¹
    sector_codes = np.random.randint(1, 34, size=n_firms)
    
    # ì¢Œí‘œ: ëŒ€í•œë¯¼êµ­ ë²”ìœ„ (ìœ„ë„ 33~43, ê²½ë„ 124~132)
    latitudes = np.random.uniform(33, 43, size=n_firms)
    longitudes = np.random.uniform(124, 132, size=n_firms)
    
    firm_info = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': firm_ids,
        'ì‚°ì—…ì½”ë“œ': sector_codes,
        'ìœ„ë„': latitudes,
        'ê²½ë„': longitudes,
        'ê¸°ì—…ëª…': [f'Company_{i}' for i in range(n_firms)]
    })
    
    firm_info.to_csv(
        output_path / "vat_20-24_company_list_w_companyinfo_nocutoff_v3_hyundaisteel_hj.csv",
        index=False
    )
    logger.info(f"   âœ“ ê¸°ì—… ì •ë³´ CSV ì €ì¥")
    
    # 5. ë§¤ì¶œ ë°ì´í„°
    logger.info("5ï¸âƒ£ ë§¤ì¶œ ë°ì´í„° ìƒì„±...")
    
    # ë¡œê·¸ì •ê·œë¶„í¬ë¡œ ë§¤ì¶œ ìƒì„± (í˜„ì‹¤ì )
    revenues = np.random.lognormal(mean=20, sigma=2, size=n_firms)  # ì²œì› ë‹¨ìœ„
    
    revenue_df = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': firm_ids,
        'tg_2024_final': revenues
    })
    
    revenue_df.to_csv(output_path / "tg_2024_filtered.csv", index=False)
    logger.info(f"   âœ“ tg_2024_filtered.csv ì €ì¥")
    
    # ë§¤ì¶œ ì¶”ì • (ì¼ë¶€ë§Œ)
    revenue_est = revenue_df.sample(frac=0.3, random_state=42)
    revenue_est.to_csv(output_path / "final_tg_2024_estimation.csv", index=False)
    logger.info(f"   âœ“ final_tg_2024_estimation.csv ì €ì¥")
    
    # 6. ìˆ˜ì¶œì•¡ (ì„ íƒì )
    logger.info("6ï¸âƒ£ ìˆ˜ì¶œì•¡ ë°ì´í„° ìƒì„±...")
    export_values = revenues * np.random.uniform(0, 0.5, size=n_firms)  # ë§¤ì¶œì˜ 0~50%
    
    export_df = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'export_value': export_values
    })
    
    export_df.to_csv(output_path / "export_estimation_value_final.csv", index=False)
    logger.info(f"   âœ“ export_estimation_value_final.csv ì €ì¥")
    
    # 7. ìì‚° (ì„ íƒì )
    logger.info("7ï¸âƒ£ ìì‚° ë°ì´í„° ìƒì„±...")
    assets = revenues * np.random.uniform(1, 5, size=n_firms)  # ë§¤ì¶œì˜ 1~5ë°°
    
    asset_df = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'asset': assets
    })
    
    asset_df.to_csv(output_path / "asset_final_2024_6ì°¨.csv", index=False)
    logger.info(f"   âœ“ asset_final_2024_6ì°¨.csv ì €ì¥")
    
    # 8. TIS ë¦¬ìŠ¤í¬ ì ìˆ˜ (ì„ íƒì )
    logger.info("8ï¸âƒ£ TIS ì ìˆ˜ ìƒì„±...")
    tis_scores = np.random.beta(2, 5, size=n_firms)  # 0~1 ì‚¬ì´, ë‚®ì€ ê°’ì— í¸ì¤‘
    
    tis_df = pd.DataFrame({
        'ì—…ì²´ë²ˆí˜¸': [f'biz_{i:06d}' for i in range(n_firms)],
        'TIS': tis_scores
    })
    
    tis_df.to_csv(output_path / "shock_after_P_v2.csv", index=False)
    logger.info(f"   âœ“ shock_after_P_v2.csv ì €ì¥")
    
    logger.info("=" * 70)
    logger.info("âœ… ë”ë¯¸ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_path.absolute()}")
    logger.info("=" * 70)
    logger.info("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ Phase 1 ì‹¤í–‰:")
    logger.info("    python main_phase1.py")
    logger.info("=" * 70)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ë”ë¯¸ ë°ì´í„° ìƒì„±")
    parser.add_argument('--n_firms', type=int, default=10000, help='ê¸°ì—… ìˆ˜')
    parser.add_argument('--density', type=float, default=0.01, help='H í–‰ë ¬ ë°€ë„')
    parser.add_argument('--output_dir', type=str, default='data/raw', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    generate_dummy_data(
        n_firms=args.n_firms,
        density=args.density,
        output_dir=args.output_dir
    )
